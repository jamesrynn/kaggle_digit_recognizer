{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer\n",
    "\n",
    "Description of kaggle competition.\n",
    "\n",
    "## 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data\n",
    "\n",
    "### 2.1. Preamble/Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Number of classes into which we shall categorise our examples.\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Load Data \n",
    "\n",
    "Load the MNIST data set keras datsets (already split into training and test data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Pre-Process Data\n",
    "\n",
    "First we reshape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we convert the data from integer to floating point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescale data values from (0,255) to (0,1) to speed up convergence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display information about data to confirm dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert class vectors to binary class matrices (map values in 0,1,...,9 to unit vectors in R^10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Convolutional Neural Net\n",
    "\n",
    "### 3.1. Define Net Structure\n",
    "\n",
    "Use keras Sequential module to build net layer by layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train\n",
    "\n",
    "Set the batch size and number of epochs to be used in training the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 70s 1ms/step - loss: 0.2640 - accuracy: 0.9177 - val_loss: 0.0552 - val_accuracy: 0.9826\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.0855 - accuracy: 0.9749 - val_loss: 0.0435 - val_accuracy: 0.9852\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.0633 - accuracy: 0.9814 - val_loss: 0.0359 - val_accuracy: 0.9874\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.0514 - accuracy: 0.9843 - val_loss: 0.0319 - val_accuracy: 0.9894\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 72s 1ms/step - loss: 0.0445 - accuracy: 0.9864 - val_loss: 0.0287 - val_accuracy: 0.9907\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.0390 - accuracy: 0.9882 - val_loss: 0.0267 - val_accuracy: 0.9922\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0356 - accuracy: 0.9893 - val_loss: 0.0269 - val_accuracy: 0.9914\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 76s 1ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.0274 - val_accuracy: 0.9906\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0295 - accuracy: 0.9913 - val_loss: 0.0285 - val_accuracy: 0.9912\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0283 - accuracy: 0.9909 - val_loss: 0.0274 - val_accuracy: 0.9918\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0257 - accuracy: 0.9921 - val_loss: 0.0267 - val_accuracy: 0.9916\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0246 - val_accuracy: 0.9922\n",
      "Test loss: 0.02464261918073562\n",
      "Test accuracy: 0.9922000169754028\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Save Model to File\n",
    "\n",
    "Save model to JSON file and weights to HDF5 file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Serialize model to JSON.\n",
    "model_json = model.to_json()\n",
    "with open('./models/model_keras_cnn_mnist_default.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# Serialize weights to HDF5.\n",
    "model.save_weights('./weights/model_keras_cnn_mnist_default.h5')\n",
    "\n",
    "# Output message.\n",
    "print('Saved model to disk.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load model at a later date..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load json and create model.\n",
    "# json_file = open('./models/model_keras_cnn_mnist_default.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# # Load weights into new model.\n",
    "# loaded_model.load_weights('model.h5')\n",
    "\n",
    "# print('Loaded model from disk.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kaggle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "ktest = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# Reshape the data.\n",
    "ktest = ktest.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ktest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using model.\n",
    "predictions = model.predict(ktest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary matrices into labels.\n",
    "predictions = np.argmax(predictions,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add label to column (ready for submission).\n",
    "predictions = pd.Series(predictions,name='Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ImageID column (for submission).\n",
    "predictions = pd.concat([pd.Series(range(1,28001),name='ImageId'),predictions], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save submission as .csv file.\n",
    "predictions.to_csv('./submissions/keras_cnn_mnist_default.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
